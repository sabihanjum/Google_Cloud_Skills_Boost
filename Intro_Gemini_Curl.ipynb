{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijGzTHJJUCPY"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPC2X_a9ErW7"
   },
   "source": [
    "# Getting Started with the Gemini API in Vertex AI with cURL\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgetting-started%2Fintro_gemini_curl.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
    "    </a>\n",
    "  </td>       \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/getting-started/intro_gemini_curl.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "<b>Share to:</b>\n",
    "\n",
    "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/53/X_logo_2023_original.svg\" alt=\"X logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
    "</a>            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0cc0f48513b"
   },
   "source": [
    "| | |\n",
    "|-|-|\n",
    "|Author(s) | [Eric Dong](https://github.com/gericdong), [Polong Lin](https://github.com/polong-lin) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axauUzNXEl_R"
   },
   "source": [
    "## Overview\n",
    "\n",
    "### Gemini\n",
    "Gemini is a family of generative AI models developed by Google DeepMind. Gemini models support prompts that include text, image, and video as input and support text responses as output.\n",
    "\n",
    "### Gemini API in Vertex AI\n",
    "\n",
    "The Gemini API in Vertex AI provides a unified interface for interacting with Gemini models. You can interact with the Gemini API by using the following methods:\n",
    "\n",
    "* Use [Vertex AI Studio](https://cloud.google.com/generative-ai-studio) for quick testing and command generation.\n",
    "* Use cURL commands in Cloud Shell.\n",
    "* Use the Vertex AI SDK for Python in a Jupyter notebook\n",
    "\n",
    "This notebook focuses on using the **cURL commands** to call the Gemini API in Vertex AI.\n",
    "\n",
    "For more information, see the [Generative AI on Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview) documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyaOZAg_El_R"
   },
   "source": [
    "### Objectives\n",
    "\n",
    "In this tutorial, you learn how to use the Gemini API in Vertex AI with cURL commands to interact with the Gemini 2.0 Flash (`gemini-2.0-flash-001`) model.\n",
    "\n",
    "You will complete the following tasks:\n",
    "\n",
    "- Install the Python SDK.\n",
    "- Use the Gemini API in Vertex AI to interact with each model.\n",
    "  - Gemini 2.0 Flash (`gemini-2.0-flash-001`) model:\n",
    "    - Generate text from text prompts.\n",
    "    - Explore various features and configuration options.\n",
    "    - Generate text from image(s) and text prompts.\n",
    "    - Generate text from video.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJf9sLIIEl_S"
   },
   "source": [
    "### Costs\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "- Vertex AI\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D50ekWXjEl_S"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you are running this notebook on Google Colab, run the following cell to authenticate your environment.\n",
    "\n",
    "This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NyKGtVQjgx13",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Additional authentication is required for Google Colab\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Authenticate user to Google Cloud\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6ZGaZlxP9L0"
   },
   "source": [
    "### Set Google Cloud project\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u8IivOG5SqY6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"qwiklabs-gcp-02-eea14a3dab2f\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-east1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8s84m7h6HSTR"
   },
   "source": [
    "### Defining environment variables for cURL commands\n",
    "\n",
    "These environment variables are used to construct the cURL commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "krJ8UOHKoPn3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PROJECT_ID\"] = PROJECT_ID\n",
    "os.environ[\"LOCATION\"] = LOCATION\n",
    "os.environ[\"API_ENDPOINT\"] = f\"{LOCATION}-aiplatform.googleapis.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "854fbf388e2b"
   },
   "source": [
    "## Use the Gemini 2.0 Flash model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7eeb063ac6d4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"MODEL_ID\"] = \"gemini-2.0-flash-001\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZZUVBSzc0cR"
   },
   "source": [
    "### Generate content\n",
    "\n",
    "The generateContent method can handle a wide variety of use cases, including multi-turn chat and multimodal input, depending on what the underlying model supports. In this example, you send a text prompt using the `generateContent` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1979afec8834",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  2903    0  2802  100   101   1356     48  0:00:02  0:00:02 --:--:--  1405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"The sky is blue because of a phenomenon called **Rayleigh scattering**. Here's a breakdown:\\n\\n*   **Sunlight and the Atmosphere:** Sunlight is made up of all the colors of the rainbow. When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\\n\\n*   **Scattering:** This collision causes the sunlight to scatter in different directions.\\n\\n*   **Rayleigh Scattering:** Rayleigh scattering is the type of scattering that affects light whose wavelength is much larger than the size of the particles it's scattering off of (in this case, air molecules). Importantly, the amount of scattering is inversely proportional to the fourth power of the wavelength of light. This means that shorter wavelengths (blue and violet light) are scattered much more strongly than longer wavelengths (red and orange light).\\n\\n*   **Why Blue, Not Violet?** While violet light has an even shorter wavelength than blue light and would be scattered more, there are a couple of reasons why we see a blue sky:\\n    *   The sun emits less violet light than blue light.\\n    *   Our eyes are more sensitive to blue light than violet light.\\n    *   Violet light is absorbed more by the upper atmosphere.\\n\\n*   **What We See:** Because blue light is scattered so much more than other colors, it's scattered all over the sky. When we look up, we see this scattered blue light coming from all directions. This makes the sky appear blue to our eyes.\\n\\nIn summary: Sunlight hits the atmosphere, blue light is scattered more than other colors due to Rayleigh scattering, and we see a blue sky.\\n\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"citationMetadata\": {\n",
      "        \"citations\": [\n",
      "          {\n",
      "            \"startIndex\": 153,\n",
      "            \"endIndex\": 291\n",
      "          },\n",
      "          {\n",
      "            \"startIndex\": 626,\n",
      "            \"endIndex\": 748,\n",
      "            \"uri\": \"https://brainly.com/question/52085859\"\n",
      "          },\n",
      "          {\n",
      "            \"startIndex\": 711,\n",
      "            \"endIndex\": 834,\n",
      "            \"uri\": \"https://turnontips.in/2024/08/17/why-is-the-sky-blue/\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"avgLogprobs\": -0.228302001953125\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 6,\n",
      "    \"candidatesTokenCount\": 338,\n",
      "    \"totalTokenCount\": 344,\n",
      "    \"trafficType\": \"ON_DEMAND\",\n",
      "    \"promptTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 6\n",
      "      }\n",
      "    ],\n",
      "    \"candidatesTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 338\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T02:59:05.718962Z\",\n",
      "  \"responseId\": \"-db5Z_LwK57ZjNsPutT2WQ\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": { \"text\": \"Why is the sky blue?\" }\n",
    "    }\n",
    "  }'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27701e417da6"
   },
   "source": [
    "### Streaming\n",
    "\n",
    "The Gemini API provides a streaming response mechanism. With this approach, you don't need to wait for the complete response; you can start processing fragments as soon as they're accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rzkCij_iS0we",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"The\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T02:59:16.219789Z\",\n",
      "  \"responseId\": \"BNf5Z421DZ7ZjNsPutT2WQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" sky is blue\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T02:59:16.219789Z\",\n",
      "  \"responseId\": \"BNf5Z421DZ7ZjNsPutT2WQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" because of a phenomenon called **Rayleigh scattering**. Here's a breakdown of why\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T02:59:16.219789Z\",\n",
      "  \"responseId\": \"BNf5Z421DZ7ZjNsPutT2WQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" it works:\\n\\n*   **Sunlight is a Mixture of Colors:** Sunlight appears\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T02:59:16.219789Z\",\n",
      "  \"responseId\": \"BNf5Z421DZ7ZjNsPutT2WQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" white, but it's actually made up of all the colors of the rainbow. Each color has a different wavelength, with red having the longest and violet the\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T02:59:16.219789Z\",\n",
      "  \"responseId\": \"BNf5Z421DZ7ZjNsPutT2WQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" shortest.\\n\\n*   **Atmospheric Particles:** Earth's atmosphere is filled with tiny particles like nitrogen and oxygen molecules.\\n\\n*   **Scattering:** When sunlight\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T02:59:16.219789Z\",\n",
      "  \"responseId\": \"BNf5Z421DZ7ZjNsPutT2WQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" enters the atmosphere, it collides with these particles. This causes the light to scatter in different directions.\\n\\n*   **Rayleigh Scattering is Wavelength-Dependent:** Rayleigh scattering is much more effective at scattering shorter wavelengths of light (blue\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T02:59:16.219789Z\",\n",
      "  \"responseId\": \"BNf5Z421DZ7ZjNsPutT2WQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" and violet) than longer wavelengths (red and orange). The amount of scattering is inversely proportional to the fourth power of the wavelength. This means blue light is scattered about ten times more than red light.\\n\\n*   **Why Blue, Not Violet\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T02:59:16.219789Z\",\n",
      "  \"responseId\": \"BNf5Z421DZ7ZjNsPutT2WQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100  6925    0  6824  100   101   2506     37  0:00:02  0:00:02 --:--:--  2542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            \"text\": \"?** While violet has the shortest wavelength and is scattered even more than blue, the sun emits less violet light than blue light. Additionally, our eyes are more sensitive to blue light than violet. This combination results in us perceiving the sky as blue.\\n\\n**In simpler terms:**\\n\\nImagine throwing different sized balls (colors\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T02:59:16.219789Z\",\n",
      "  \"responseId\": \"BNf5Z421DZ7ZjNsPutT2WQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" of light) at a bunch of small obstacles (air molecules). The smaller balls (blue light) will bounce around more easily than the larger balls (red light). So, the blue light gets scattered all over the place, making the sky appear blue.\\n\\n**Important Considerations:**\\n\\n*   **Sunrise and Sunset:** At\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T02:59:16.219789Z\",\n",
      "  \"responseId\": \"BNf5Z421DZ7ZjNsPutT2WQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \" sunrise and sunset, the sunlight has to travel through much more of the atmosphere to reach our eyes. This means that most of the blue light has already been scattered away, leaving the longer wavelengths (reds, oranges, and yellows) to dominate. That's why we see beautiful red and orange skies during these times.\\n\\n\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"trafficType\": \"ON_DEMAND\"\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T02:59:16.219789Z\",\n",
      "  \"responseId\": \"BNf5Z421DZ7ZjNsPutT2WQ\"\n",
      "}\n",
      ",\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"*   **Other Factors:** The amount of water vapor, dust, and other particles in the atmosphere can also affect the color of the sky. For example, a hazy or polluted sky may appear whiter because these larger particles scatter all colors of light more equally.\\n\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finishReason\": \"STOP\"\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 6,\n",
      "    \"candidatesTokenCount\": 446,\n",
      "    \"totalTokenCount\": 452,\n",
      "    \"trafficType\": \"ON_DEMAND\",\n",
      "    \"promptTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 6\n",
      "      }\n",
      "    ],\n",
      "    \"candidatesTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 446\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T02:59:16.219789Z\",\n",
      "  \"responseId\": \"BNf5Z421DZ7ZjNsPutT2WQ\"\n",
      "}\n",
      "]"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:streamGenerateContent \\\n",
    "  -d '{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": { \"text\": \"Why is the sky blue?\" }\n",
    "    }\n",
    "  }'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3e56BV7PH9t8"
   },
   "source": [
    "### Model parameters\n",
    "\n",
    "Every prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. You can experiment with different model parameters to see how the results change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Px8hSHhiH9t8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  3457    0  2854  100   603   1232    260  0:00:02  0:00:02 --:--:--  1493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Here's a description of the image:\\n\\n**Overall Impression:**\\n\\nThe image shows a tabby cat standing in a snowy environment. The cat is the main subject and is in focus, while the background is a blur of white snow.\\n\\n**Cat Details:**\\n\\n*   **Coat:** The cat has a classic tabby coat pattern, with dark brown or black stripes on a lighter brown background.\\n*   **Eyes:** The cat has yellow or golden eyes.\\n*   **Pose:** The cat is standing with one paw slightly raised, as if it's about to take a step. It's looking directly at the camera with a curious or alert expression.\\n*   **Build:** The cat appears to be of average build, not overly thin or overweight.\\n\\n**Background:**\\n\\n*   The background is entirely snow-covered. There are some subtle variations in the snow's texture, suggesting footprints or other disturbances.\\n*   The background is out of focus, which helps to emphasize the cat as the main subject.\\n\\n**Overall Tone:**\\n\\nThe image has a natural and slightly cold feel due to the snowy environment. The cat's alert expression adds a touch of curiosity and liveliness to the scene.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"safetyRatings\": [\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probabilityScore\": 3.004989e-05,\n",
      "          \"severity\": \"HARM_SEVERITY_NEGLIGIBLE\",\n",
      "          \"severityScore\": 0.050032675\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probabilityScore\": 0.00029752046,\n",
      "          \"severity\": \"HARM_SEVERITY_NEGLIGIBLE\"\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probabilityScore\": 3.293895e-05,\n",
      "          \"severity\": \"HARM_SEVERITY_NEGLIGIBLE\",\n",
      "          \"severityScore\": 0.021136705\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probabilityScore\": 1.01153555e-05,\n",
      "          \"severity\": \"HARM_SEVERITY_NEGLIGIBLE\"\n",
      "        }\n",
      "      ],\n",
      "      \"avgLogprobs\": -0.24356434631347657\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 261,\n",
      "    \"candidatesTokenCount\": 250,\n",
      "    \"totalTokenCount\": 511,\n",
      "    \"trafficType\": \"ON_DEMAND\",\n",
      "    \"promptTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"IMAGE\",\n",
      "        \"tokenCount\": 258\n",
      "      },\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 3\n",
      "      }\n",
      "    ],\n",
      "    \"candidatesTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 250\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T02:59:30.451382Z\",\n",
      "  \"responseId\": \"Etf5Z7bGG57ZjNsPutT2WQ\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": [\n",
    "        {\"text\": \"Describe this image\"},\n",
    "        {\"file_data\": {\n",
    "          \"mime_type\": \"image/png\",\n",
    "          \"file_uri\": \"gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\"\n",
    "        }}\n",
    "      ]\n",
    "    },\n",
    "    \"generation_config\": {\n",
    "      \"temperature\": 0.2,\n",
    "      \"top_p\": 0.1,\n",
    "      \"top_k\": 16,\n",
    "      \"max_output_tokens\": 2048,\n",
    "      \"candidate_count\": 1,\n",
    "      \"stop_sequences\": []\n",
    "    },\n",
    "    \"safety_settings\": {\n",
    "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
    "    }\n",
    "  }'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4-XhmPn_Pb-"
   },
   "source": [
    "### Chat\n",
    "\n",
    "The Gemini API supports natural multi-turn conversations and is ideal for text tasks that require back-and-forth interactions.\n",
    "\n",
    "Specify the `role` field only if the content represents a turn in a conversation. You can set `role` to one of the following values: `user`, `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YqSQSK-K-KVU",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1836    0  1438  100   398   1173    324  0:00:01  0:00:01 --:--:--  1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Alright, let's get down to business! To best answer that, I need a little more context.  What kind of meeting is this?  Knowing the purpose will help me suggest a relevant first order of business.\\n\\nFor example:\\n\\n*   **If this is a project meeting:** The first order of business could be a quick review of the agenda or a check-in on outstanding action items from the last meeting.\\n*   **If this is a general catch-up:** We could start with brief introductions or a round-robin sharing of updates.\\n*   **If this is a problem-solving meeting:**  We might start by clearly defining the problem we're trying to solve.\\n\\nTell me what this meeting is about, and I'll give you a more specific suggestion!\\n\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"avgLogprobs\": -0.45023715857303503\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 21,\n",
      "    \"candidatesTokenCount\": 165,\n",
      "    \"totalTokenCount\": 186,\n",
      "    \"trafficType\": \"ON_DEMAND\",\n",
      "    \"promptTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 21\n",
      "      }\n",
      "    ],\n",
      "    \"candidatesTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 165\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T02:59:41.828774Z\",\n",
      "  \"responseId\": \"Hdf5Z-bKMoGEjNsP0r6tmQw\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "          { \"text\": \"Hello\" }\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"model\",\n",
    "        \"parts\": [\n",
    "          { \"text\": \"Hello! I am glad you could both make it.\" }\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "          { \"text\": \"So what is the first order of business?\" }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f0f5fe3b331"
   },
   "source": [
    "### Function calling\n",
    "\n",
    "Function calling lets you create a description of a function in their code, then pass that description to a language model in a request. This sample is an example of passing in a description of a function that returns information about where a movie is playing. Several function declarations are included in the request, such as `find_movies` and `find_theaters`.\n",
    "\n",
    "Learn more about [function calling](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "680b11b0ba4c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  3478    0   915  100  2563   1859   5209 --:--:-- --:--:-- --:--:--  7054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"functionCall\": {\n",
      "              \"name\": \"find_theaters\",\n",
      "              \"args\": {\n",
      "                \"movie\": \"Barbie\",\n",
      "                \"location\": \"Mountain View, CA\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"avgLogprobs\": -0.036088038574565544\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 191,\n",
      "    \"candidatesTokenCount\": 11,\n",
      "    \"totalTokenCount\": 202,\n",
      "    \"trafficType\": \"ON_DEMAND\",\n",
      "    \"promptTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 191\n",
      "      }\n",
      "    ],\n",
      "    \"candidatesTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 11\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T02:59:49.099300Z\",\n",
      "  \"responseId\": \"Jdf5Z-SHBp7ZjNsPutT2WQ\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}/v1beta1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \\\n",
    "  -d '{\n",
    "  \"contents\": {\n",
    "    \"role\": \"user\",\n",
    "    \"parts\": {\n",
    "      \"text\": \"Which theaters in Mountain View show Barbie movie?\"\n",
    "    }\n",
    "  },\n",
    "  \"tools\": [\n",
    "    {\n",
    "      \"function_declarations\": [\n",
    "        {\n",
    "          \"name\": \"find_movies\",\n",
    "          \"description\": \"find movie titles currently playing in theaters based on any description, genre, title words, etc.\",\n",
    "          \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n",
    "              },\n",
    "              \"description\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any kind of description including category or genre, title words, attributes, etc.\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\n",
    "              \"description\"\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"find_theaters\",\n",
    "          \"description\": \"find theaters based on location and optionally movie title which are is currently playing in theaters\",\n",
    "          \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n",
    "              },\n",
    "              \"movie\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any movie title\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\n",
    "              \"location\"\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"get_showtimes\",\n",
    "          \"description\": \"Find the start times for movies playing in a specific theater\",\n",
    "          \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n",
    "              },\n",
    "              \"movie\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any movie title\"\n",
    "              },\n",
    "              \"theater\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Name of theater\"\n",
    "              },\n",
    "              \"date\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Date for requested showtime\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\n",
    "              \"location\",\n",
    "              \"movie\",\n",
    "              \"theater\",\n",
    "              \"date\"\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3g5n23lDtsN"
   },
   "source": [
    "## Multimodal input\n",
    "\n",
    "The Gemini 2.0 Flash  (`gemini-2.0-flash-001`) is a multimodal model that supports adding image and video in text or chat prompts for a text response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTfL2DDch4Lp"
   },
   "source": [
    "### Download an image from Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KmtWSNLtJ7oD",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg...\n",
      "/ [1 files][ 17.4 KiB/ 17.4 KiB]                                                \n",
      "Operation completed over 1 objects/17.4 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp \"gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\" ./image.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlyyaPgmhpyv"
   },
   "source": [
    "### Generate text from a local image\n",
    "\n",
    "Specify the [base64](https://en.wikipedia.org/wiki/Base64) encoding of the image or video to include inline in the prompt and the `mime_type` field. The supported [MIME types](https://en.wikipedia.org/wiki/Media_type) for images include `image/png` and `image/jpeg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-uqZ-RWdtdit",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 24955    0   861  100 24094    900  25202 --:--:-- --:--:-- --:--:-- 26076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Yes, the image shows a cat. It appears to be a tabby cat.\\n\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"avgLogprobs\": -0.14220588347491095\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 263,\n",
      "    \"candidatesTokenCount\": 17,\n",
      "    \"totalTokenCount\": 280,\n",
      "    \"trafficType\": \"ON_DEMAND\",\n",
      "    \"promptTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 5\n",
      "      },\n",
      "      {\n",
      "        \"modality\": \"IMAGE\",\n",
      "        \"tokenCount\": 258\n",
      "      }\n",
      "    ],\n",
      "    \"candidatesTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 17\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T03:00:08.603644Z\",\n",
      "  \"responseId\": \"ONf5Z_zrJNKgjNsP2NCR2A8\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Encode image data in base64\n",
    "# NOTE: This command only works on Linux.\n",
    "data=$(base64 -w 0 image.jpg)\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \\\n",
    "  -d \"{\n",
    "      'contents': {\n",
    "        'role': 'USER',\n",
    "        'parts': [\n",
    "          {\n",
    "            'text': 'Is it a cat?'\n",
    "          },\n",
    "          {\n",
    "            'inline_data': {\n",
    "              'data': '${data}',\n",
    "              'mime_type':'image/jpeg'\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "       }\n",
    "     }\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKr-BklmhjgP"
   },
   "source": [
    "### Generate text from an image on Google Cloud Storage\n",
    "\n",
    "Specify the Cloud Storage URI of the image to include in the prompt. The bucket that stores the file must be in the same Google Cloud project that's sending the request. You must also specify the `mime_type` field. The supported image MIME types include `image/png` and `image/jpeg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "43pQE3_z3OjG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  3497    0  2848  100   649   1358    309  0:00:02  0:00:02 --:--:--  1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Here's a description of the image:\\n\\n**Overall Impression:**\\n\\nThe image shows a tabby cat standing in the snow. The cat is the main subject and is in focus, while the snowy background is slightly blurred.\\n\\n**Cat's Appearance:**\\n\\n*   **Coat:** The cat has a classic tabby coat pattern, with dark brown or black stripes on a lighter brown background.\\n*   **Eyes:** The cat has yellow or golden eyes.\\n*   **Pose:** The cat is standing with one paw slightly raised, as if it's about to take a step. It's looking directly at the viewer with a curious or alert expression.\\n*   **Build:** The cat appears to be of average size and build.\\n\\n**Background:**\\n\\n*   The background is entirely snow-covered.\\n*   There are some tracks or indentations in the snow, suggesting that something has moved through the area.\\n*   The background is out of focus, which helps to emphasize the cat as the main subject.\\n\\n**Overall Tone:**\\n\\nThe image has a natural and slightly cold feel due to the snow. The cat's alert expression adds a touch of curiosity and interest.\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"safetyRatings\": [\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probabilityScore\": 2.4570247e-05,\n",
      "          \"severity\": \"HARM_SEVERITY_NEGLIGIBLE\",\n",
      "          \"severityScore\": 0.05213207\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probabilityScore\": 0.00027674725,\n",
      "          \"severity\": \"HARM_SEVERITY_NEGLIGIBLE\",\n",
      "          \"severityScore\": 0.0071991086\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probabilityScore\": 4.5237626e-05,\n",
      "          \"severity\": \"HARM_SEVERITY_NEGLIGIBLE\",\n",
      "          \"severityScore\": 0.07015994\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probabilityScore\": 8.572794e-06,\n",
      "          \"severity\": \"HARM_SEVERITY_NEGLIGIBLE\"\n",
      "        }\n",
      "      ],\n",
      "      \"avgLogprobs\": -0.22093708271882972\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 261,\n",
      "    \"candidatesTokenCount\": 245,\n",
      "    \"totalTokenCount\": 506,\n",
      "    \"trafficType\": \"ON_DEMAND\",\n",
      "    \"promptTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"IMAGE\",\n",
      "        \"tokenCount\": 258\n",
      "      },\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 3\n",
      "      }\n",
      "    ],\n",
      "    \"candidatesTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 245\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T03:00:16.194044Z\",\n",
      "  \"responseId\": \"QNf5Z_zrC57ZjNsPutT2WQ\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "MODEL_ID=\"gemini-2.0-flash-001\"\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": [\n",
    "        {\n",
    "          \"text\": \"Describe this image\"\n",
    "        },\n",
    "        {\n",
    "          \"file_data\": {\n",
    "            \"mime_type\": \"image/png\",\n",
    "            \"file_uri\": \"gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    \"generation_config\": {\n",
    "      \"temperature\": 0.2,\n",
    "      \"top_p\": 0.1,\n",
    "      \"top_k\": 16,\n",
    "      \"max_output_tokens\": 2048,\n",
    "      \"candidate_count\": 1,\n",
    "      \"stop_sequences\": []\n",
    "    },\n",
    "    \"safety_settings\": {\n",
    "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
    "    }\n",
    "  }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVF4vHuBOD8N"
   },
   "source": [
    "### Generate text from a video file\n",
    "\n",
    "Specify the Cloud Storage URI of the video to include in the prompt. The bucket that stores the file must be in the same Google Cloud project that's sending the request. You must also specify the `mime_type` field. The supported MIME types for video include `video/mp4`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "F8kS5p0l_uHE",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1578    0  1064  100   514    268    129  0:00:03  0:00:03 --:--:--   398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"role\": \"model\",\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"```json\\n{\\n  \\\"profession\\\": \\\"Photographer\\\",\\n  \\\"phone_features\\\": \\\"Video Boost -Night Sight works in low light to make the quality even better.\\\",\\n  \\\"city\\\": \\\"Tokyo\\\"\\n}\\n```\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"avgLogprobs\": -0.37551744778951007\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 16285,\n",
      "    \"candidatesTokenCount\": 48,\n",
      "    \"totalTokenCount\": 16333,\n",
      "    \"trafficType\": \"ON_DEMAND\",\n",
      "    \"promptTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 40\n",
      "      },\n",
      "      {\n",
      "        \"modality\": \"VIDEO\",\n",
      "        \"tokenCount\": 14820\n",
      "      },\n",
      "      {\n",
      "        \"modality\": \"AUDIO\",\n",
      "        \"tokenCount\": 1425\n",
      "      }\n",
      "    ],\n",
      "    \"candidatesTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 48\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-2.0-flash-001\",\n",
      "  \"createTime\": \"2025-04-12T03:00:26.144354Z\",\n",
      "  \"responseId\": \"Stf5Z-LnCJ7ZjNsPutT2WQ\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}/v1/projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/${MODEL_ID}:generateContent \\\n",
    "  -d \\\n",
    "'{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": [\n",
    "        {\n",
    "          \"text\": \"Answer the following questions using the video only. What is the profession of the main person? What are the main features of the phone highlighted?Which city was this recorded in?Provide the answer JSON.\"\n",
    "        },\n",
    "        {\n",
    "          \"file_data\": {\n",
    "            \"mime_type\": \"video/mp4\",\n",
    "            \"file_uri\": \"gs://github-repo/img/gemini/multimodality_usecases_overview/pixel8.mp4\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "intro_gemini_curl.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
